{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1306e941-16e3-49f8-96e6-7c284314f02a",
   "metadata": {},
   "source": [
    "https://data.mendeley.com/datasets/cyhchpxwps/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32cdcd8c-b181-4e20-afa2-5ab554ff81ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9203ca6f-c6af-4527-8e44-b2994baea1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ac22ff-8b7a-40f5-86e7-cb88c8b6cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Control - no negative feedback/EEG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Control - no negative feedback/Linear ECG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Control - no negative feedback/Nonlinear ECG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Control - no negative feedback/Ratio of Alpha _ Beta Power.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Experiment - with negative feedback/EEG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Experiment - with negative feedback/Linear ECG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Experiment - with negative feedback/Nonlinear ECG.xlsx\n",
      "Attempting to load: /Users/hannahmanheimer/Downloads/Dataset/Experiment - with negative feedback/Ratio of Alpha _ Beta Power.xlsx\n",
      "Combined data shape: (662, 94)\n",
      "Epoch 1/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 2/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 3/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 4/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 5/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 6/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 7/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 8/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 9/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 10/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 11/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 12/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 13/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 14/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 15/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 16/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 17/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 18/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 19/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 20/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 21/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 22/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 23/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 24/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 25/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 26/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 27/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 28/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 29/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Epoch 30/30, Loss: nan, Test Accuracy: 50.38%\n",
      "Final Test Accuracy: 50.38%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_norm, labels, test_size = 0.2, random_state = 42, stratify = labels\n",
    ")\n",
    "\n",
    "\n",
    "file_names = [\n",
    "    \"EEG.xlsx\",\n",
    "    \"Linear ECG.xlsx\",\n",
    "    \"Nonlinear ECG.xlsx\",\n",
    "    \"Ratio of Alpha _ Beta Power.xlsx\"\n",
    "]\n",
    "\n",
    "control_dir = \"/Users/hannahmanheimer/Downloads/Dataset/Control - no negative feedback\"\n",
    "experiment_dir = \"/Users/hannahmanheimer/Downloads/Dataset/Experiment - with negative feedback\"\n",
    "\n",
    "def load_data_from_folder(folder, file_names):\n",
    "    data_frames = []\n",
    "    for file in file_names:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        #needed to debug\n",
    "        print(\"Attempting to load:\", file_path)\n",
    "        df = pd.read_excel(file_path)\n",
    "        prefix = os.path.splitext(file)[0]\n",
    "        df = df.add_prefix(prefix + \"_\")\n",
    "        data_frames.append(df)\n",
    "    data = pd.concat(data_frames, axis = 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "#load the data\n",
    "control_data = load_data_from_folder(control_dir, file_names)\n",
    "experiment_data = load_data_from_folder(experiment_dir, file_names)\n",
    "\n",
    "#combine the datasets\n",
    "#use 0 and 1 to consider for the negative feedback and no negative feedback\n",
    "control_data[\"label\"] = 0\n",
    "experiment_data[\"label\"] = 1\n",
    "\n",
    "#combine datasets into one\n",
    "full_data = pd.concat([control_data, experiment_data], axis=0).reset_index(drop=True)\n",
    "print(\"Combined data shape:\", full_data.shape)\n",
    "\n",
    "#preprocess\n",
    "features = full_data.drop(\"label\", axis = 1).select_dtypes(include=[np.number]).values\n",
    "labels = full_data[\"label\"].values\n",
    "\n",
    "# Normalize with min-max scaling\n",
    "feat_min = features.min(axis = 0)\n",
    "feat_max = features.max(axis = 0)\n",
    "features_norm = (features - feat_min) / (feat_max - feat_min + 1e-8)\n",
    "\n",
    "\n",
    "#use pytorch\n",
    "class StressDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype = torch.float32)\n",
    "        self.y = torch.tensor(y, dtype = torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = StressDataset(X_train, y_train)\n",
    "test_dataset  = StressDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#define simple neural network classifier\n",
    "class StressClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, num_classes=2):\n",
    "        super(StressClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = StressClassifier(input_dim = input_dim, hidden_dim = 32, num_classes = 2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    \n",
    "    \n",
    "    #test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "    acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "#final model eval\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "final_acc = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "print(\"Final Test Accuracy: {:.2f}%\".format(final_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9f807-4255-49e3-8487-17f65a45cdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_name)",
   "language": "python",
   "name": "env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
